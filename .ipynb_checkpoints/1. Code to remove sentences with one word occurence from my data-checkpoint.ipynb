{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import ngrams\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['iji', 'ubube', 'eme', 'ihe', 'ì', 'na', 'eme', 'nnyocha', 'ndị', 'a']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file= open(\"my_corpus.txt\",encoding= \"utf8\")\n",
    "#file= open(\"test.ig.txt\",encoding= \"utf8\")\n",
    "\n",
    "filex= file.read()\n",
    "#filet= filex.lower()\n",
    "#filet= re.sub(r\"[^A-Za-z àáéèọíìịị̀ụụ́ụ̀úù]\",'',filet)#Use regex to clean sentence\n",
    "file= filex.split()\n",
    "file[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ede59b314d6e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstuff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mget_char\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filet' is not defined"
     ]
    }
   ],
   "source": [
    "x= \"Iji Ubube Eme Ihe — Ị̀ Na - eme Nnyocha Ndị A Iji Zere Mmerụ Ahụ ?\"\n",
    "\n",
    "\n",
    "#Code to get Characters in the file\n",
    "\n",
    "def get_char(my_file):\n",
    "    stuff=[]\n",
    "    for x in my_file:\n",
    "        stuff.append(x)\n",
    "    return set(stuff)\n",
    "\n",
    "get_char(filet)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow= Counter(file)\n",
    "bow['chineke']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_1_words(arr_of_sentences):\n",
    "    \n",
    "    a_list= []\n",
    "    list_of_single_word_sent= []\n",
    "    \n",
    "    for sent in arr_of_sentences:\n",
    "        #print(sent)\n",
    "        for word in sent.split():\n",
    "            #print (bow[word])\n",
    "            if bow[word]<=1:\n",
    "                #print(sent)\n",
    "                print(f'Word:{word:{12}}   |   Index:{arr_of_sentences.index(sent):{3}}  |   freq:{bow[word]:{3}}')\n",
    "                #print(arr_of_sentences.index(sent))\n",
    "                #a_list.append(arr_of_sentences.pop(arr_of_sentences.index(sent)))\n",
    "                a_list.append(arr_of_sentences.index(sent))\n",
    "                \n",
    "                \n",
    "    #print(arr_of_sentences)       \n",
    "    for x in set(a_list):\n",
    "        list_of_single_word_sent.append(arr_of_sentences[x])\n",
    "    \n",
    "    for i in list_of_single_word_sent:\n",
    "        arr_of_sentences.remove(i)\n",
    "\n",
    "    return arr_of_sentences\n",
    "    #return set(a_list)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search1= ['akụkọ ndị gaamasị gị',\n",
    " 'joseph achuzie dike biafra alala',\n",
    " 'dapchi gọọmenti emeribeghị boko haram  massob',\n",
    " 'tottenham naele anya iburu iko fa na mmeri rochadale',\n",
    " 'son heungmin fernando llorente na kyle walterpeters nke tottenham bụ ndị mmechiri ọnụ rochadale nasọmpị ụnyaahụ',\n",
    " 'son heungmin onye tottenham na ndị otu ya nanwe anụrị mgbe o nyere goolu nasọmpị iko fa',\n",
    " 'tottenham emerila nasọmpị iko fa ugboro asatọ',\n",
    " 'negwuregwu ndị otu tottenham gbara ndị rochadale ọkpụ goolu isii asatara otu nasọmpi fa',\n",
    " 'son heungmin nyere goolu nke mbụ na nke ise fernando llorente nyere goolu atọ nime nkeji iri na abụọ nokara nke abụọ ebe kyle walterpeters nyere goolu nke isi',\n",
    " 'son heungmin kwụsị bọọlụ otu rochadale']\n",
    "\n",
    "''' \n",
    "for w in search:\n",
    "    search.pop(search.index(w))\n",
    "       \n",
    "#search.pop(3)\n",
    "search.pop(4)\n",
    "\n",
    "len(search)\n",
    "search\n",
    "'''\n",
    "#hmm= {0, 1, 2, 3}\n",
    "#hmm2=[]\n",
    "\n",
    "#for i in hmm:\n",
    "    #hmm2.append(search1[i])\n",
    "    #del search1[i] #using del means as the loop is updating the indexes are changing and it is del that way\n",
    "    \n",
    "#hmm2\n",
    "\n",
    "#for i in hmm2:\n",
    "    #search1.remove(i)\n",
    "    \n",
    "#search1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= remove_1_words(search1)\n",
    "#x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(search1)\n",
    "#len(ans)\n",
    "x= 'akụkọ ndị gaamasị gị'\n",
    "x.split()\n",
    "\n",
    "y=[0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3]\n",
    "set(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning My Dataset\n",
    "\n",
    "The codes below perform the ffg funtion\n",
    "\n",
    "1. cleaner(): Removes symbols and use lower()\n",
    "2. remove_rare_words(): Remove words with less than one occurence\n",
    "3. removes spaces in the text using .strip().replace(\"  \",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import ngrams\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A code to remove puntuations and symbols except ('), and to bring data to a lower case\n",
    "\n",
    "def cleaner(a_sentence):\n",
    "    \n",
    "    sentence= a_sentence.split('\\n') #split data into sentences\n",
    "    new_array=[]\n",
    "    \n",
    "    for sent in sentence:\n",
    "        #print(sent)\n",
    "        if re.search(r'\\d', sent) or len(sent) < 2: #Ignore sentences with numbers, and len <2\n",
    "            #print(sent)\n",
    "            pass\n",
    "        else:\n",
    "            clean_punct= re.sub(r\"[^\\w\\s]\",'',sent) #remove punctuations and symbols except (’)\n",
    "            #clean_punct= re.sub(r\"[^\\w\\s’]\",'',sent) #remove punctuations and symbols except (’)\n",
    "            #clean_punct= re.sub(r\"[^A-Za-z àáéèọíìịị̀ụụ́ụ̀úùṅṇÄÁÀÉÈỌỌ̀ÒÓỊ̀ỊÌỤÚṄŃḾ’']\",'',sent)\n",
    "            new_array.append(clean_punct.lower())\n",
    "            #sentence.remove(sent)\n",
    "                  \n",
    "    new_array=new_array[:]\n",
    "    #return new_array\n",
    "    return \"\\n\".join(new_array)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A neat version of the code without the tests\n",
    "\n",
    "# CHATGPT code to remove one_word occurence\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def remove_rare_words(corpus):\n",
    "    # Split the corpus into sentences\n",
    "    #sentences = re.split(r'[.!?]', corpus)\n",
    "    sentences = corpus.split('\\n')\n",
    "    \n",
    "    # Create a Counter object to count the occurrences of each word\n",
    "    word_counts = Counter()\n",
    "    for sentence in sentences:\n",
    "        for word in sentence.split():\n",
    "            word_counts[word] += 1\n",
    "            \n",
    "    #print (word_counts)\n",
    "    # Remove sentences that contain words that occur only once\n",
    "    #new_corpus = \"\"\n",
    "    new_corpus=[]\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        include_sentence = True\n",
    "        for word in sentence.split():\n",
    "            if word_counts[word] == 1:\n",
    "                include_sentence = False\n",
    "                break\n",
    "        if include_sentence:\n",
    "            #new_corpus += sentence + \" \" \n",
    "            new_corpus.append(sentence)\n",
    "    \n",
    "        \n",
    "    #return new_corpus.strip()\n",
    "    return \"\\n\".join(new_corpus),word_counts # returning the \"x\".strip().replace(\"  \",\" \") to remove extra spaces does not work when used within the function\n",
    "    \n",
    "\n",
    "#corpus = \"This is a sentence. This is another sentence. This is a unique sentence.\"\n",
    "#print(remove_rare_words(corpus))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'senta' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-fb8f0dcaf3b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#x= remove_rare_words(senta)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mcleaner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msenta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#print(senta)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#print (x)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'senta' is not defined"
     ]
    }
   ],
   "source": [
    "#x= remove_rare_words(senta)\n",
    "x= cleaner(senta)\n",
    "\n",
    "#print(senta)\n",
    "#print (x)\n",
    "\n",
    "#print(cleaner(x))\n",
    "print (remove_rare_words(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-663779c458ad>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-663779c458ad>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    y=\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "x = {'na': 135, 'ọ': 75, 'ya': 58, 'ubube': 41, 'ahụ': 41, 'ka': 39, 'ị': 39, 'ma': 38, 'ihe': 37, 'a': 34, 'ndị': 32, 'dị': 32, 'nke': 29, 'mgbe': 29, 'ga': 28, 'bụrụ': 22, 'gị': 19, 'bụ': 18, 'ha': 17, 'ebe': 16, 'eme': 15, 'ọrụ': 15, 'e': 15, 'mmadụ': 15, 'aka': 14, 'mee': 13, 'iji': 12, 'elu': 12, 'pụrụ': 12, 'ụkwụ': 12, 'ike': 12, 'i': 12, 'ji': 11, 'o': 10, 'n’elu': 10, 'n’ihe': 10, 'otu': 10, 'anya': 9, 'arụ': 8, 'otú': 8, 'ò': 8, 'azọdo': 8, 'bụla': 8, 'nile': 8, 'ala': 8, 'adịla': 8, 'site': 7, 'abụọ': 7, 'n’ihi': 6, 'eji': 6, 'n’ebe': 6, 'apịachi': 6, 'aga': 6, 'buru': 6, 'jiri': 6, 'jide': 6, 'mmerụ': 5, 'onye': 5, 'ụlọ': 5, 'oge': 5, 'rụọ': 5, 'ọma': 5, 'ókè': 5, 'ogologo': 5, 'n’ime': 5, 'kegide': 5, 'ọzọ': 5, 'paul': 4, 'eletrik': 4, 'nwere': 4, 'daa': 4, 'ukwuu': 4, 'banyere': 4, 'ime': 4, 'ghaghị': 4, 'kwesịrị': 4, 'n’ubube': 4, 'hụ': 4, 'nanị': 4, 'gafee': 4, 'atọ': 4, 'mbụ': 4, 'n’ala': 4, 'ngwá': 4, 'zere': 3, 'n’aka': 3, 'mkpa': 3, 'bọlb': 3, 'n’ihu': 3, 'ịkpata': 3, 'ụzọ': 3, 'si': 3, 'tupu': 3, 'mma': 3, 'onwe': 3, 'ize': 3, 'ndụ': 3, 'arịba': 3, 'ekwesị': 3, 'agbabewe': 3, 'osisi': 3, 'kọrọ': 3, 'ghara': 3, 'hà': 3, 'ọnụ': 3, 'eriri': 3, 'nakwa': 3, 'n’ụzọ': 3, 'ụgbọala': 3, 'n’azụ': 3, 'mfe': 3, 'ịhụ': 3, 'n’ubu': 3, 'ọchị': 3, 'adịghị': 3, 'mere': 3, 'maka': 3, 'larịị': 3, 'rụnyere': 3, 'arịgo': 3, 'nọ': 3, 'ekwe': 3, 'ọbụna': 3, 'ọhụrụ': 3, 'ịtọrọ': 3, 'ì': 2, 'nnyocha': 2, 'ọkụ': 2, 'dịkwa': 2, 'ihicha': 2, 'windo': 2, 'n’ụlọ': 2, 'n’èzí': 2, 'gịnị': 2, 'ezi': 2, 'isi': 2, 'aro': 2, 'iri': 2, 'nyeere': 2, 'n’emerụghị': 2, 'ịbụ': 2, 'ịgbatị': 2, 'gabiga': 2, 'dịkarịrị': 2, 'n’uko': 2, 'debe': 2, 'aṅagharị': 2, 'egosi': 2, 'adị': 2, 'n’okpuru': 2, 'jikọtara': 2, 'inwe': 2, 'mkpọre': 2, 'chọrọ': 2, 'oghere': 2, 'tinyere': 2, 'egbochi': 2, 'dịkarịa': 2, 'ná': 2, 'dịrị': 2, 'agbatị': 2, 'bu': 2, 'were': 2, 'ihu': 2, 'n’uche': 2, 'n’ogologo': 2, 'guzowere': 2, 'arọ': 2, 'kpachara': 2, 'amị': 2, 'eguzowe': 2, 'arụnye': 2, 'mita': 2, 'rịgoro': 2, 'nrịgo': 2, 'ikpeazụ': 2, 'bú': 2, 'gwa': 2, 'siri': 2, 'yiri': 2, 'emi': 2, 'anọ': 2, 'n’ike': 2, 'mịchapụ': 2, 'arị': 2, 'ọsọ': 2, 'ọnọdụ': 2, 'nwee': 2, 'ngwa': 2, 'mara': 2, 'ruo': 2, 'n’oge': 2, 'zuru': 2, 'ụwa': 2, 'gara': 2, 'omempụ': 2, 'ntọ': 2, 'agagharị': 2, 'anụ': 2, 'nta': 1, 'akụkọ': 1, 'teta': 1, 'ireland': 1, 'ịgbanwe': 1, 'nwunye': 1, 'ekwuwo': 1, 'ọtụtụ': 1, 'ugboro': 1, 'nọgidere': 1, 'eyigharị': 1, 'uche': 1, 'ịtụ': 1, 'egwu': 1, 'maara': 1, 'ọbụnakwa': 1, 'ọnwụ': 1, 'echeghị': 1, 'echiche': 1, 'ziri': 1, 'tụlee': 1, 'mkpụmkpụ': 1, 'ịgbabiwe': 1, 'è': 1, 'debere': 1, 'agbasa': 1, 'dere': 1, 'mmiri': 1, 'akpachikọlatakwa': 1, 'mmirị': 1, 'isikwa': 1, 'gbawara': 1, 'agbawa': 1, 'ereela': 1, 'enwekarị': 1, 'ígwè': 1, 'sie': 1, 'sikwara': 1, 'ntú': 1, 'kụdo': 1, 'agbajiela': 1, 'taa': 1, 'nchara': 1, 'akaala': 1, 'rụzie': 1, 'nrụzi': 1, 'gbanwee': 1, 'mgbanwe': 1, 'ozugbo': 1, 'etinyekarị': 1, 'ịmịchapụ': 1, 'wepụrụ': 1, 'unyi': 1, 'ijupụta': 1, 'n’ụkwụ': 1, 'ichipụ': 1, 'echipụ': 1, 'emebibeghị': 1, 'emebi': 1, 'ekedo': 1, 'adọkpụ': 1, 'ịpụta': 1, 'ákwà': 1, 'ịdọ': 1, 'ntị': 1, 'eso': 1, 'akasị': 1, 'eburịrị': 1, 'chọọ': 1, 'jidesie': 1, 'kwụzie': 1, 'ịkụ': 1, 'bulie': 1, 'ogo': 1, 'azụ': 1, 'kụrụ': 1, 'nkiri': 1, 'yie': 1, 'bịa': 1, 'n’ezie': 1, 'karịsịa': 1, 'ọtọ': 1, 'weliekwa': 1, 'kwụrụ': 1, 'lezie': 1, 'waya': 1, 'saịn': 1, 'bọọdụ': 1, 'dịghị': 1, 'ugegbe': 1, 'plastik': 1, 'kwere': 1, 'kegidesie': 1, 'gbabewere': 1, 'nnọọ': 1, 'kegidere': 1, 'adịkwa': 1, 'arịdata': 1, 'ketusịrị': 1, 'adịkarịghị': 1, 'nyere': 1, 'irè': 1, 'akarịghị': 1, 'ise': 1, 'kpọdara': 1, 'akpọda': 1, 'hinye': 1, 'guzoro': 1, 'ibé': 1, 'gbadosiri': 1, 'gbasaa': 1, 'pịchie': 1, 'ịpịachi': 1, 'nchebe': 1, 'okpuru': 1, 'akpụkpọ': 1, 'wepụ': 1, 'apịtị': 1, 'ịrịgo': 1, 'tinye': 1, 'akpa': 1, 'belt': 1, 'n’úkwù': 1, 'gbalịa': 1, 'ịchọta': 1, 'esi': 1, 'ebugo': 1, 'obubu': 1, 'ejirịrị': 1, 'ejighị': 1, 'ejide': 1, 'n’ịdị': 1, 'achị': 1, 'n’akụkụ': 1, 'nwayọọ': 1, 'arikwala': 1, 'atụ': 1, 'akpọpu': 1, 'ịtọ': 1, 'wee': 1, 'nọhie': 1, 'agbachi': 1, 'ịda': 1, 'agafe': 1, 'bụrụkwa': 1, 'gebichie': 1, 'iburu': 1, 'gbagọrọ': 1, 'agbagọ': 1, 'enweta': 1, 'mberede': 1, 'kwuo': 1, 'okwu': 1, 'leekwa': 1, 'nọchiri': 1, 'rịgoo': 1, 'obere': 1, 'screwdriver': 1, 'ịpụ': 1, 'nweghị': 1, 'ikegide': 1, 'legide': 1, 'tọgbọ': 1, 'agaghị': 1, 'emerụ': 1, 'lọghachiri': 1, 'ahapụla': 1, 'n’enweghị': 1, 'legidere': 1, 'nkwụzi': 1, 'n’usoro': 1, 'enye': 1, 'ịrị': 1, 'arịla': 1, 'arịa': 1, 'ọrịa': 1, 'agbọ': 1, 'enu': 1, 'ájù': 1, 'ebu': 1, 'nọrọ': 1, 'lee': 1, 'ezere': 1, 'karịa': 1, 'rịa': 1, 'oké': 1, 'ifufe': 1, 'eguzo': 1, 'edebe': 1, 'afọdụ': 1, 'amatịbiga': 1, 'gbatịbiga': 1, 'anọhie': 1, 'kama': 1, 'merụọ': 1, 'bugharịa': 1, 'ewe': 1, 'karịrị': 1, 'ele': 1, 'n’agbanyeghị': 1, 'akpacharu': 1, 'enwe': 1, 'ikekwe': 1, 'inyere': 1, 'ibelata': 1, 'n’ịgbaso': 1, 'n’ọkụ': 1, 'gịnikwa': 1, 'eleghị': 1, 'achụmnta': 1, 'ego': 1, 'afọ': 1, 'amụbawo': 1, 'gburugburu': 1, 'mpụ': 1, 'ewuru': 1, 'n’ụwa': 1, 'russia': 1, 'philippines': 1, 'njikere': 1, 'ịnwụde': 1, 'n’otu': 1, 'tọọrọ': 1, 'nwa': 1, 'ụbọchị': 1, 'ụmụ': 1, 'anụmanụ': 1, 'eyighị': 1, 'nweere': 1, 'sịrị': 1, 'òtù': 1, 'mexico': 1, 'agba': 1, 'batara': 1, 'n’òtù': 1, 'ume': 1, 'enyi': 1, 'amụgharị': 1, 'nweta': 1, 'ahụmahụ': 1, 'ezu': 1, 'ebido': 1, 'ezigbo': 1}\n",
    "\n",
    "y= Counter({'na': 135, 'ọ': 75, 'ya': 58, 'ubube': 41, 'ahụ': 41, 'ka': 39, 'ị': 39, 'ma': 38, 'ihe': 37, 'a': 34, 'ndị': 32, 'dị': 32, 'nke': 29, 'mgbe': 29, 'ga': 28, 'bụrụ': 22, 'gị': 19, 'bụ': 18, 'ha': 17, 'ebe': 16, 'eme': 15, 'ọrụ': 15, 'e': 15, 'mmadụ': 15})\n",
    "y=\n",
    "x['agbabewe']\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaner(remove_rare_words(x))\n",
    "\n",
    "ọ bụ n’ihi na ọ ga  eji ubube rụọ ha \n",
    "ndị a bụ aro iri nyeere ya aka ime ihe n’emerụghị ahụ \n",
    "zere iji ubube a na  apịachi apịachi arịba n’uko ụlọ gị \n",
    "ubube abụọ e jikọtara ọnụ pụrụ inwe ihe mkpọre na eriri \n",
    "ihe mkpọre ndị ahụ hà na  arụ ọrụ nke ọma \n",
    "kpachara anya maka ebe ị na  agbabewe ebe elu ubube \n",
    "ọ bụrụ na i ji ngwá ọrụ ji ike eletrik eme ihe na  arụ ọrụ  ya adịla mgbe ị ga  eji aka abụọ jide ya ka ị na  arụ ọrụ \n",
    "\n",
    "remove_rare_words(cleaner(x))\n",
    "iji ubube eme ihe  ì na  eme nnyocha ndị a iji zere mmerụ ahụ \n",
    "n’ihi gịnị \n",
    "ọ bụ n’ihi na ọ ga  eji ubube rụọ ha \n",
    "ndị a bụ aro iri nyeere ya aka ime ihe n’emerụghị ahụ \n",
    "ubube ahụ ò dị mma \n",
    "zere iji ubube a na  apịachi apịachi arịba n’uko ụlọ gị \n",
    "debe ubube kwesịrị ekwesị a ga na  eji arịba n’uko ụlọ gị  ma ọ bụ na  eji ubube a na  agbabewe agbabewe arịba \n",
    "ubube abụọ e jikọtara ọnụ pụrụ inwe ihe mkpọre na eriri \n",
    "ihe mkpọre ndị ahụ hà na  arụ ọrụ nke ọma \n",
    "kpachara anya maka ebe ị na  agbabewe ebe elu ubube \n",
    "ọ bụrụ na i ji ngwá ọrụ ji ike eletrik eme ihe na  arụ ọrụ  ya adịla mgbe ị ga  eji aka abụọ jide ya ka ị na  arụ ọrụ \n",
    "ha nyeere paul aka \n",
    "n’oge gara aga  ndị ntọ na  e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open jw300.ig.text file for cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file= open(\"jw300.ig.txt\", encoding=\"utf8\")\n",
    "#file= open(\"test.ig.txt\", encoding=\"utf8\")\n",
    "#file= open(\"text_file_modified.txt\", encoding=\"utf8\")\n",
    "\n",
    "sent= file.read()\n",
    "#sent= sent.split('\\n')\n",
    "#sent= re.sub(r\"[^\\w\\s'][’]\",'',sent)\n",
    "senta=sent[:10000]\n",
    "#senta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iji ubube eme ihe ì na eme nnyocha ndị a iji zere mmerụ ahụ \\nsite naka onye nta akụkọ teta \\nna irela'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#half_clean_file2, diction= cleaner(remove_rare_words(sent))\n",
    "\n",
    "half_clean_file, diction= remove_rare_words(cleaner(sent)) \n",
    "\n",
    "Cleaned_file= half_clean_file.strip().replace(\"  \",\" \")\n",
    "Cleaned_file[:100]\n",
    "\n",
    "#Cleaned_file_araba= clean_file_for_araba_data.strip().replace(\"  \",\" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diction[\"myrtle\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file= open('my_corpus.txt', 'w+', encoding='utf8')#half_clean_file\n",
    "#file= open('my_corpus2.txt', 'w+', encoding='utf8')#half_clean_file2\n",
    "#file= open('test.ig.with.errors.txt', 'w+', encoding='utf8')#half_clean_file\n",
    "#file= open('test.ig.txt', 'w+', encoding='utf8')#half_clean_file\n",
    "\n",
    "\n",
    "file.write(Cleaned_file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets for Araba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Igbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the section for the dataset, I want to give to Araba for data validation\n",
    "\n",
    "clean_file_for_araba_data= remove_rare_words(sent)\n",
    "\n",
    "Cleaned_file_araba= clean_file_for_araba_data.strip().replace(\"  \",\" \")\n",
    "\n",
    "file= open('my_corpus_araba.txt', 'w+', encoding='utf8')\n",
    "file.write(Cleaned_file_araba)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file= open(\"jw300.en.txt\", encoding=\"utf8\")\n",
    "file= open(\"test.ig.txt\", encoding=\"utf8\")\n",
    "\n",
    "sent= file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the section for the dataset, I want to give Araba for data validation English\n",
    "clean_file_for_araba_data= remove_rare_words(sent)\n",
    "\n",
    "Cleaned_file_araba= clean_file_for_araba_data.strip().replace(\"  \",\" \")\n",
    "\n",
    "file= open('my_corpus_araba_eng.txt', 'w+', encoding='utf8')\n",
    "file.write(Cleaned_file_araba)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iji ubube eme ihe ì na eme nnyocha ndị a iji zere mmerụ ahụ \\nsite n’aka onye nta akụkọ teta'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tesing Cleaner\n",
    "x='Iji Ubube Eme Ihe — Ị̀ Na - eme Nnyocha Ndị A Iji Zere Mmerụ Ahụ ?\\nSite n’aka onye nta akụkọ Teta !'\n",
    "y= cleaner(x)\n",
    "\n",
    "z= '  iji ubube eme ihe  ì na  eme nnyocha ndị a iji zere mmerụ ahụ \\nsite n’aka onye nta akụkọ teta '\n",
    "q= z.strip().replace(\"  \",\" \")\n",
    "\n",
    "q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to keep the (') in the data\n",
    "#x= \"Iguzo mwuli akọn////auche nke ndị mmadụ site n'ịchọ mgbanwe abụghị ịda iwu\"\n",
    "x= \"Ọ bụ n’ihi na ọ ga - eji ubube rụọ ha\"\n",
    "#x= \"Iji Ubube Eme Ihe — Ị̀ Na - eme Nnyocha Ndị A Iji Zere Mmerụ Ahụ ?\"\n",
    "#x= re.sub(r\"[^A-Za-z àáéèọíìịị̀ụụ́ụ̀úùṅṇÄÁÀÉÈỌỌ̀ÒÓỊ̀ỊÌỤÚṄŃḾ’]\",'',x)\n",
    "x= re.sub(r\"[^\\w\\s'][’]\",'',x) # this is the better code \n",
    "x\n",
    "\n",
    "#the method works for the dummy datasets but not for the jwIg300.txt dataset, why is because I have not completed the regex\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
